## Суть

**Вычислительная сложность метода исключения Гаусса** характеризует количество арифметических операций, требуемых для решения системы $n$ линейных уравнений с $n$ неизвестными. Для прямого хода требуется примерно $n^3/3$ операций, что является оптимальной оценкой среди простых методов.

Стренг подчёркивает практическую важность подсчёта операций: «Какое количество арифметических операций требует метод исключения для решения системы $n$ уравнений с $n$ неизвестными?» Это очень практический и финансовый вопрос.

---

## Детали

### Определение операции

**Операция** в контексте исключения — это пара **умножение-вычитание** или **умножение-сложение**:
- Умножение строки на множитель;
- Вычитание (или сложение) результата с другой строкой.

Деление также считается за одну операцию, но в процессе исключения делений существенно меньше.

### Подсчёт для прямого хода

**На первом шаге** исключаем первую неизвестную из $(n-1)$ уравнений:
- Для каждого из $(n-1)$ уравнений выполняем операции с $n$ коэффициентами;
- Операций: $(n-1) \times n = n^2 - n$.

**На втором шаге** исключаем вторую неизвестную из $(n-2)$ уравнений:
- Операций: $(n-2) \times (n-1)$

**На $k$-м шаге**:
- Операций: $(n-k) \times (n-k+1)$

**Общее число операций для прямого хода**:
$$
P = \sum_{k=1}^{n-1} (n-k)(n-k+1) = \sum_{j=1}^{n-1} j(j+1)
$$

где $j = n - k$.

### Вывод формулы $P \approx n^3/3$

Раскроем сумму:
$$
P = \sum_{j=1}^{n-1} (j^2 + j) = \sum_{j=1}^{n-1} j^2 + \sum_{j=1}^{n-1} j
$$

Используем формулы:
- $\sum_{j=1}^{m} j^2 = \frac{m(m+1)(2m+1)}{6}$
- $\sum_{j=1}^{m} j = \frac{m(m+1)}{2}$

Для $m = n-1$:
$$
P = \frac{(n-1)n(2n-1)}{6} + \frac{(n-1)n}{2}
$$

При больших $n$:
$$
P \approx \frac{n \cdot n \cdot 2n}{6} + \frac{n^2}{2} = \frac{n^3}{3} + \frac{n^2}{2} \approx \frac{n^3}{3}
$$

### Подсчёт для обратной подстановки

Обратная подстановка требует:
$$
Q = \sum_{k=1}^{n} k = \frac{n(n+1)}{2} \approx \frac{n^2}{2}
$$

Это **пренебрежимо мало** по сравнению с $n^3/3$ при больших $n$.

### Общая сложность

**Полная сложность метода исключения**:
$$
\text{Прямой ход} + \text{Обратная подстановка} = \frac{n^3}{3} + \frac{n^2}{2}
$$

**Доминирующий член**: $n^3/3$

**Порядок роста**: $O(n^3)$

### Практическая интерпретация

Для конкретных значений $n$:

| $n$  | $n^3/3$     | Примерное время* |
|------|-------------|------------------|
| 10   | 333         | микросекунды     |
| 100  | 333,333     | миллисекунды     |
| 1000 | 333,333,333 | секунды          |
| 10000| 3.3×10¹¹    | минуты           |

*При 1 GFLOPS (10⁹ операций/сек)

---

## Примеры

### Конкретный пример для $n=3$

Для системы $3 \times 3$:

**Прямой ход**:
- Шаг 1: $(3-1) \times 3 = 6$ операций;
- Шаг 2: $(3-2) \times 2 = 2$ операции;
- Итого: $P = 6 + 2 = 8$ операций.

По формуле: $P = \frac{3^3}{3} = 9$ (приближение даёт 9 вместо точных 8)

**Обратная подстановка**:
$$
Q = 1 + 2 + 3 = 6
$$

**Всего**: $8 + 6 = 14$ операций

### Сравнение с правилом Крамера

Для $n=10$:
- **Исключение**: $\approx 333$ операции;
- **Правило Крамера**: $11 \times 10! \approx 40,000,000$ операций;
- **Отношение**: $\approx 120,000$ раз медленнее!

### Масштабирование на больших системах

Удвоение размера системы ($n \to 2n$):
$$
\frac{(2n)^3/3}{n^3/3} = \frac{8n^3}{n^3} = 8
$$

Время решения **увеличивается в 8 раз** при удвоении размера.

---

## Источник

- Документ: [[Линейная алгебра и ее применения.pdf]]
- Раздел/страницы: § 1.2, стр. 15–16
- Ключевая цитата:
  
  > «Какое количество арифметических операций требует метод исключения для решения системы $n$ уравнений с $n$ неизвестными?.. Число операций в левой части уравнений вычисляется по формуле $P = (n^2-n) + \ldots + (k^2-k) + \ldots + (1^2-1)$... Окончательно $P = \frac{n^3}{3} + \frac{n^2}{2} + n(\frac{n^2}{2}) = \frac{n^3}{3}$».

---

## Вопросы

- Как изменится сложность для разреженных матриц (с большим числом нулей)?
- Можно ли уменьшить константу перед $n^3$ за счёт других алгоритмов?
- Какова сложность для блочных матриц специального вида?
- Как распараллеливание влияет на реальное время вычислений?
- Почему алгоритмы с лучшей асимптотикой (типа Штрассена) не всегда выгодны?