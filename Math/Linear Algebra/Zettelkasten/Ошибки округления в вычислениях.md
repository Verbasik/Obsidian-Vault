## Суть

**Ошибки округления** — это неизбежные погрешности, возникающие при представлении вещественных чисел в компьютере с **конечной точностью**. В методе исключения Гаусса ошибки округления накапливаются на каждом шаге, и при неудачном выборе ведущего элемента могут привести к катастрофической потере точности.

Для системы среднего размера (порядка ста) каждое число описывается мантиссой из $m$ цифр и показателем степени $c$, т.е. $n = m \times 10^c$. Число цифр в $m$ равно длине машинного слова. **Без какого-либо анализа ошибок** для вычислений с плавающей точкой можно указать на **очевидный факт**: если в арифметике с плавающей точкой складываются два числа и их экспоненты с различаются, то последние две цифры в меньшем числе будут потеряны.

---

## Детали

### Природа ошибок округления

**Представление чисел в компьютере**:

Вещественное число представляется в **форме с плавающей точкой**:
$$
x = \pm m \times 10^c \quad \text{или} \quad x = \pm m \times 2^c
$$

где:
- $m$ — **мантисса** (имеет фиксированное число значащих цифр, например, 15-16 в double precision);
- $c$ — **экспонента** (показатель степени).

**Машинный эпсилон** $\epsilon_{\text{machine}}$ — наименьшее число, для которого $1 + \epsilon_{\text{machine}} \neq 1$ в арифметике компьютера.

Для double precision (64 бита): $\epsilon_{\text{machine}} \approx 2.22 \times 10^{-16}$

### Источники ошибок в методе Гаусса

**1. Вычитание близких чисел** (катастрофическое сокращение):

Если $a = 1.234567$ и $b = 1.234566$, то $a - b = 0.000001$ — **потеряны 6 значащих цифр**!

В методе исключения:
$$
a_{ij}^{new} = a_{ij} - l_{ik} \cdot a_{kj}
$$

Если $a_{ij} \approx l_{ik} \cdot a_{kj}$, происходит катастрофическое сокращение.

**2. Деление на малое число**:

Если ведущий элемент $a_{kk}$ очень мал, множитель:
$$
l_{ik} = \frac{a_{ik}}{a_{kk}}
$$
может быть **огромным**, что усиливает ошибки округления.

**Пример** (из книги Стренга):

В десятичной системе с 3 значащими цифрами:
$$
0.345 + 0.00123 \to 0.346
$$

Последние две цифры меньшего числа ($23$) **потеряны**.

**3. Накопление ошибок**:

Каждая операция вносит малую ошибку порядка $\epsilon_{\text{machine}}$. После $\approx n^3/3$ операций (сложность метода Гаусса) **суммарная ошибка** может стать значительной.

### Влияние выбора ведущего элемента

**Без выбора ведущего элемента** (наивный метод):

Ведущий элемент может быть очень мал → множители огромны → ошибки катастрофичны.

**С частичным выбором**:

Все множители $|l_{ik}| \leq 1$ → ошибки **контролируются** → метод **численно устойчив** для большинства матриц.

**Пример из книги**:

Две системы с матрицами $A$ и $A'$, отличающимися на $0.0001$:
$$
A = \begin{bmatrix} 1 & 1 \\ 1 & 1.0001 \end{bmatrix}, \quad
A' = \begin{bmatrix} 1 & 1 \\ 1 & 1 \end{bmatrix}
$$

Решение для $A$: единственное

Решение для $A'$: бесконечно много (вырожденная матрица!)

**Чувствительность**: Малое изменение данных → драматическое изменение решения.

### Анализ ошибок

**Прямая ошибка** (forward error): Разность между точным и вычисленным решением:
$$
\|x_{\text{exact}} - x_{\text{computed}}\|
$$

**Обратная ошибка** (backward error): Насколько нужно изменить данные, чтобы вычисленное решение было точным для изменённой системы.

**Связь с обусловленностью**:
$$
\frac{\|x_{\text{exact}} - x_{\text{computed}}\|}{\|x_{\text{exact}}\|} \approx \kappa(A) \cdot \epsilon_{\text{machine}}
$$

где $\kappa(A)$ — **число обусловленности** матрицы.

### Практические следствия

**Для системы порядка $n = 100$**:

С плавающей точкой двойной точности ($\epsilon_{\text{machine}} \approx 10^{-16}$):

Ожидаемая относительная ошибка: $\approx 10^{-16} \times 100^3 \approx 10^{-10}$

**Потеря точности**: примерно **6 десятичных знаков** из 16.

**Вывод**: даже при хорошей реализации невозможно получить более 10 точных знаков для систем порядка сотни.

---

## Примеры

### Пример из книги: сложение с разными экспонентами

**Арифметика с 3 значащими цифрами** (десятичная):

$$
0.345 + 0.00123 = 0.34623 \to 0.346 \text{ (округление)}
$$

**Потеря**: последние две цифры меньшего числа ($2$ и $3$) потеряны.

Если таких операций много, потери накапливаются.

### Пример: катастрофическое сокращение

**Точные числа**:
$$
a = 1.2345678, \quad b = 1.2345670
$$

**Разность**:
$$
a - b = 0.0000008
$$

**В 8-разрядной арифметике**:
$$
a = 1.2345678, \quad b = 1.2345670 \quad \text{(округлены до 8 знаков)}
$$
$$
a - b = 0.0000008
$$

Результат имеет только **1 значащую цифру** вместо 8!

### Пример: малый ведущий элемент (повтор из заметки 32)

Система с $\epsilon = 10^{-10}$:
$$
\begin{bmatrix}
10^{-10} & 1 \\
1 & 1
\end{bmatrix}
\begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
= \begin{bmatrix} 1 \\ 2 \end{bmatrix}
$$

**Без перестановки** (в арифметике с 10 знаками):

Множитель: $l_{21} = \frac{1}{10^{-10}} = 10^{10}$

Вычисление: $a_{22}^{new} = 1 - 10^{10} \cdot 1 = -9999999999$

В ограниченной точности: огромные числа, потери точности.

**С перестановкой** (частичный выбор):

Множитель: $l_{21} = \frac{10^{-10}}{1} = 10^{-10}$ (очень мал!)

Вычисления стабильны, решение точное.

### Пример: плохо обусловленная матрица

**Матрица Гильберта** $H_n$:
$$
H_n = \begin{bmatrix}
1 & \frac{1}{2} & \frac{1}{3} & \cdots \\
\frac{1}{2} & \frac{1}{3} & \frac{1}{4} & \cdots \\
\frac{1}{3} & \frac{1}{4} & \frac{1}{5} & \cdots \\
\vdots & \vdots & \vdots & \ddots
\end{bmatrix}
$$

**Число обусловленности**: $\kappa(H_5) \approx 10^6$, $\kappa(H_{10}) \approx 10^{13}$

**Следствие**: даже с частичным выбором и двойной точностью решение системы $H_{10}x = b$ может потерять **все** значащие цифры!

### Численный эксперимент

**Точное решение**: $x = [1, 1]^T$

**Правая часть**: $b = Ax = [2, 2]^T$ (для какой-то матрицы $A$)

**Вычисленное решение** (с ошибками округления): $\tilde{x} = [1.0000001, 0.9999999]^T$

**Относительная ошибка**:
$$
\frac{\|x - \tilde{x}\|}{\|x\|} \approx \frac{10^{-7}}{1.41} \approx 7 \times 10^{-8}
$$

Для хорошо обусловленной матрицы — приемлемая точность.

---

## Источник

- Документ: [[Линейная алгебра и ее применения.pdf]]
- Раздел/страницы: § 1.5, стр. 48–49
- Ключевая цитата:
  
  > «Напомним, что для системы среднего размера (порядка ста) каждое число описывается мантиссой $m$ и показателем степени $c$, т.е. $n = m \times 10^c$. Число цифр в $m$ равно длине машинного слова... **Без какого-либо анализа ошибок** для вычислений с плавающей точкой можно указать на **очевидный факт**: если в арифметике с плавающей точкой складываются два числа и их экспоненты $c$ различаются, например, на два, то последние две цифры в меньшем числе будут потеряны».

---

## Вопросы

- Как оценить суммарную ошибку округления для конкретной матрицы?
- Существуют ли методы, которые полностью избегают ошибок округления?
- Как влияет порядок выполнения операций на накопление ошибок?
- Можно ли использовать арифметику произвольной точности для критических вычислений?
- Как связаны ошибки округления и разреженность матрицы?