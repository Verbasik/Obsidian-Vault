## Суть

**Обусловленность матрицы** (condition number) — это мера **чувствительности решения системы** $Ax = b$ к малым изменениям в данных (матрице $A$ или правой части $b$). Хорошо обусловленная матрица даёт стабильное решение, плохо обусловленная — решение может драматически измениться при малых возмущениях данных.

**Число обусловленности** $\kappa(A)$ определяется как:
$$
\kappa(A) = \|A\| \cdot \|A^{-1}\|
$$

Чем **больше** $\kappa(A)$, тем **хуже** обусловлена матрица, тем **труднее** получить точное решение численными методами.

---

## Детали

### Определение числа обусловленности

Для невырожденной матрицы $A$ **число обусловленности** в норме $\|\cdot\|$ определяется как:

$$
\kappa(A) = \|A\| \cdot \|A^{-1}\|
$$

**Наиболее употребительные нормы**:

**1. Спектральная норма** (норма 2):
$$
\kappa_2(A) = \|A\|_2 \cdot \|A^{-1}\|_2 = \frac{\sigma_{\max}(A)}{\sigma_{\min}(A)}
$$
где $\sigma_{\max}$ и $\sigma_{\min}$ — максимальное и минимальное сингулярные числа.

**2. Норма Фробениуса**:
$$
\kappa_F(A) = \|A\|_F \cdot \|A^{-1}\|_F
$$

**3. Норма $\infty$** (максимум сумм строк):
$$
\kappa_\infty(A) = \|A\|_\infty \cdot \|A^{-1}\|_\infty
$$

### Свойства числа обусловленности

**1. Нижняя граница**: $\kappa(A) \geq 1$ для любой матрицы

Равенство $\kappa(A) = 1$ достигается только для **ортогональных матриц** (и кратных им).

**2. Масштабирование**: Умножение на скаляр не меняет число обусловленности:
$$
\kappa(\alpha A) = \kappa(A) \quad \text{для } \alpha \neq 0
$$

**3. Для диагональной матрицы**:
$$
D = \text{diag}(d_1, \ldots, d_n) \quad \Rightarrow \quad \kappa(D) = \frac{\max |d_i|}{\min |d_i|}
$$

**4. Вырожденная матрица**: $\kappa(A) = \infty$ (так как $A^{-1}$ не существует)

### Связь с чувствительностью решения

**Теорема**: Пусть $x$ — решение системы $Ax = b$, а $\tilde{x}$ — решение возмущённой системы $A\tilde{x} = \tilde{b}$, где $\tilde{b} = b + \delta b$.

Тогда **относительная ошибка** в решении оценивается:
$$
\frac{\|\tilde{x} - x\|}{\|x\|} \leq \kappa(A) \cdot \frac{\|\delta b\|}{\|b\|}
$$

**Интерпретация**: Число обусловленности — это **коэффициент усиления** ошибки:

- $\kappa(A) = 10$ → ошибка в данных $10^{-6}$ может дать ошибку в решении до $10^{-5}$;
- $\kappa(A) = 10^{10}$ → ошибка в данных $10^{-6}$ может дать ошибку в решении до $10^4$ (катастрофа!).

### Классификация матриц

**Хорошо обусловленная**: $\kappa(A) \approx 1$ до $10^2$

Решение устойчиво к ошибкам округления.

**Умеренно обусловленная**: $\kappa(A) \approx 10^3$ до $10^6$

Решение может иметь некоторую потерю точности.

**Плохо обусловленная**: $\kappa(A) \geq 10^8$

Решение крайне чувствительно к ошибкам, численные методы ненадёжны.

**Сингулярная** (вырожденная): $\kappa(A) = \infty$

Решение не существует или не единственно.

### Потеря точности

В арифметике с машинным эпсилоном $\epsilon_{\text{machine}}$:

**Ожидаемая относительная ошибка** решения:
$$
\frac{\|\tilde{x} - x\|}{\|x\|} \approx \kappa(A) \cdot \epsilon_{\text{machine}}
$$

**Потеря значащих цифр**:
$$
\text{потеря} \approx \log_{10} \kappa(A)
$$

**Пример**: если $\kappa(A) = 10^8$ и $\epsilon_{\text{machine}} \approx 10^{-16}$, то:
- Относительная ошибка $\approx 10^{-8}$;
- Потеря **8 десятичных знаков**;
- Из 16 знаков двойной точности остаётся только **8 точных**.

### Связь с собственными значениями

Для **нормальных матриц** (в частности, симметричных):
$$
\kappa_2(A) = \frac{|\lambda_{\max}|}{|\lambda_{\min}|}
$$

где $\lambda_{\max}$ и $\lambda_{\min}$ — собственные значения с максимальным и минимальным модулем.

Если собственные значения сильно различаются по модулю → матрица плохо обусловлена.

---

## Примеры

### Пример: хорошо обусловленная матрица

**Единичная матрица**:
$$
I = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}
$$

$$
\kappa(I) = \|I\| \cdot \|I^{-1}\| = 1 \cdot 1 = 1
$$

**Идеальная обусловленность** — решение абсолютно стабильно.

**Ортогональная матрица** (например, поворот):
$$
Q = \begin{bmatrix} \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix}
$$

$$
\kappa_2(Q) = 1
$$

### Пример: плохо обусловленная матрица

**Почти сингулярная матрица**:
$$
A = \begin{bmatrix} 1 & 1 \\ 1 & 1.0001 \end{bmatrix}
$$

$$
\det(A) = 1 \cdot 1.0001 - 1 \cdot 1 = 0.0001 \text{ (очень мал!)}
$$

**Обратная матрица**:
$$
A^{-1} = \frac{1}{0.0001}\begin{bmatrix} 1.0001 & -1 \\ -1 & 1 \end{bmatrix}
= \begin{bmatrix} 10001 & -10000 \\ -10000 & 10000 \end{bmatrix}
$$

**Число обусловленности** (оценка):
$$
\kappa_\infty(A) \approx \max(\text{суммы строк } A) \times \max(\text{суммы строк } A^{-1})
$$
$$
\approx 2 \times 20001 = 40002
$$

**Вывод**: матрица **плохо обусловлена** — малое изменение данных может значительно изменить решение.

### Пример: матрица Гильберта

**Матрица Гильберта** $H_n$:
$$
[H_n]_{ij} = \frac{1}{i + j - 1}
$$

**Числа обусловленности**:
- $\kappa(H_3) \approx 524$;
- $\kappa(H_5) \approx 4.8 \times 10^5$;
- $\kappa(H_{10}) \approx 1.6 \times 10^{13}$;
- $\kappa(H_{20}) \approx 10^{18}$ю

**Вывод**: для $H_{10}$ в арифметике двойной точности ($\epsilon \approx 10^{-16}$):
$$
\text{ошибка} \approx 10^{13} \times 10^{-16} = 10^{-3}
$$

**Потеря 13 десятичных знаков** — решение практически бесполезно!

### Пример: диагональная матрица

$$
D = \begin{bmatrix} 1000 & 0 \\ 0 & 0.001 \end{bmatrix}
$$

$$
D^{-1} = \begin{bmatrix} 0.001 & 0 \\ 0 & 1000 \end{bmatrix}
$$

$$
\kappa_2(D) = \frac{1000}{0.001} = 10^6
$$

**Вывод**: большая разница между диагональными элементами → плохая обусловленность.

### Пример: влияние возмущения

Система $Ax = b$ с $A = \begin{bmatrix} 1 & 1 \\ 1 & 1.0001 \end{bmatrix}$, $b = \begin{bmatrix} 2 \\ 2.0001 \end{bmatrix}$

**Точное решение**: $x = [1, 1]^T$

**Возмущённая правая часть**: $\tilde{b} = b + [0, 0.0001]^T = [2, 2.0002]^T$

**Решение возмущённой системы**: $\tilde{x} \approx [0, 2]^T$

**Относительная ошибка**:
$$
\frac{\|x - \tilde{x}\|}{\|x\|} \approx \frac{\sqrt{2}}{\sqrt{2}} = 1 \text{ (100\%!)}
$$

**Относительное возмущение данных**:
$$
\frac{\|\delta b\|}{\|b\|} = \frac{0.0001}{2.0001} \approx 5 \times 10^{-5}
$$

**Усиление**: $\frac{1}{5 \times 10^{-5}} = 20000 \approx \kappa(A)$ ✓

---

## Источник

- Документ: [[Линейная алгебра и ее применения.pdf]]
- Раздел/страницы: § 1.5, стр. 48 (косвенное упоминание через чувствительность решений)
- Ключевая цитата:
  
  > «Одни матрицы чрезвычайно **чувствительны** к малым изменениям, а другие нет. Матрица $A$ **плохо обусловлена** (в смысле чувствительности к изменениям), а матрица $A'$ хорошо обусловлена... Изменение пятой значащей цифры в компоненте вектора $b$ привело к изменению первой значащей цифры в решении $u = 2$».

**Примечание**: Формальное определение числа обусловленности не дано в доступных страницах, но концепция чувствительности матрицы подробно обсуждается.

---

## Вопросы

- Как быстро оценить число обусловленности без вычисления $A^{-1}$?
- Можно ли улучшить обусловленность матрицы преобразованием (предобуславливанием)?
- Как обусловленность связана с геометрией линейного преобразования?
- Существуют ли эффективные алгоритмы для плохо обусловленных систем?
- Как обобщается понятие обусловленности на прямоугольные матрицы и переопределённые системы?