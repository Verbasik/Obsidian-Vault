## Суть

**Число обусловленности** $\kappa(A)$ — это количественная мера **чувствительности** решения системы $Ax = b$ к ошибкам в данных. Оно определяется как произведение норм матрицы и её обратной:

$$
\kappa(A) = \|A\| \cdot \|A^{-1}\|
$$

Число обусловленности показывает, **во сколько раз** может увеличиться относительная ошибка при переходе от данных к решению. Чем больше $\kappa(A)$, тем **менее надёжно** численное решение системы.

**Правило большого пальца**: в арифметике с точностью $\epsilon$ можно потерять до $\log_{10} \kappa(A)$ десятичных знаков точности.

---

## Детали

### Формальное определение

Для невырожденной квадратной матрицы $A$ **число обусловленности** в норме $\|\cdot\|$ определяется как:

$$
\kappa(A) = \|A\| \cdot \|A^{-1}\|
$$

**Варианты** в зависимости от выбора нормы:

**1. В спектральной норме** (норма 2, евклидова):
$$
\kappa_2(A) = \|A\|_2 \cdot \|A^{-1}\|_2 = \frac{\sigma_1(A)}{\sigma_n(A)}
$$
где $\sigma_1 \geq \sigma_2 \geq \cdots \geq \sigma_n > 0$ — сингулярные числа $A$.

**2. В норме Фробениуса**:
$$
\kappa_F(A) = \|A\|_F \cdot \|A^{-1}\|_F
$$

**3. В норме $\infty$**:
$$
\kappa_\infty(A) = \|A\|_\infty \cdot \|A^{-1}\|_\infty
$$

где $\|A\|_\infty = \max_i \sum_j |a_{ij}|$ (максимальная сумма модулей строк).

### Интерпретация через возмущения

**Теорема (Чувствительность к возмущению правой части)**:

Если $Ax = b$ и $A(x + \delta x) = b + \delta b$, то:
$$
\frac{\|\delta x\|}{\|x\|} \leq \kappa(A) \cdot \frac{\|\delta b\|}{\|b\|}
$$

**Теорема (Чувствительность к возмущению матрицы)**:

Если $Ax = b$ и $(A + \delta A)(x + \delta x) = b$ при малом $\|\delta A\|$, то:
$$
\frac{\|\delta x\|}{\|x\|} \leq \frac{\kappa(A)}{1 - \kappa(A) \frac{\|\delta A\|}{\|A\|}} \cdot \frac{\|\delta A\|}{\|A\|}
$$

**Вывод**: $\kappa(A)$ — это **коэффициент усиления ошибки** при переходе от данных к решению.

### Связь с потерей точности

В арифметике с плавающей точкой с машинной точностью $\epsilon_{\text{machine}}$:

**Ожидаемая относительная ошибка**:
$$
\frac{\|x_{\text{computed}} - x_{\text{exact}}\|}{\|x_{\text{exact}}\|} \approx \kappa(A) \cdot \epsilon_{\text{machine}}
$$

**Потеря десятичных знаков**:
$$
\text{потерянные знаки} \approx \log_{10} \kappa(A)
$$

**Примеры**:
- $\kappa(A) = 10^3$ → потеря **3 знаков**;
- $\kappa(A) = 10^8$ → потеря **8 знаков**;
- $\kappa(A) = 10^{16}$ (двойная точность) → **все знаки** могут быть неверны!

### Оценки числа обусловленности

**Нижняя граница**:
$$
\kappa(A) \geq 1
$$

Равенство достигается для **унитарных/ортогональных** матриц.

**Для диагональной матрицы**:
$$
D = \text{diag}(d_1, \ldots, d_n) \quad \Rightarrow \quad \kappa_2(D) = \frac{\max_i |d_i|}{\min_i |d_i|}
$$

**Для симметричной матрицы**:
$$
\kappa_2(A) = \frac{|\lambda_{\max}(A)|}{|\lambda_{\min}(A)|}
$$

### Вычисление числа обусловленности

**Точное вычисление**: Требует вычисления $A^{-1}$ или сингулярных чисел — дорого!

**Оценка без обращения**:

Метод на основе решения дополнительных систем:
$$
\|A^{-1}\| \approx \frac{\|y\|}{\|z\|}
$$
где $Az = y$ для некоторого тестового вектора $y$.

**Стандартные библиотеки** (LAPACK, MATLAB, NumPy) используют эффективные алгоритмы оценки $\kappa(A)$ с $O(n^2)$ дополнительными операциями после LU-разложения.

### Практическое применение

**Диагностика проблем**: Если $\kappa(A)$ велико, система плохо обусловлена:
- Решение ненадёжно;
- Малые ошибки данных → большие ошибки решения;
- Нужны специальные методы (регуляризация, предобуславливание).

**Выбор метода решения**:
- $\kappa(A) < 10^{10}$ → стандартные методы (Гаусс, LU) надёжны;
- $\kappa(A) \geq 10^{10}$ → нужны итерационные методы или регуляризация.

---

## Примеры

### Пример: вычисление для матрицы 2×2

$$
A = \begin{bmatrix} 4 & 3 \\ 3 & 2 \end{bmatrix}
$$

**Обратная матрица**:
$$
A^{-1} = \frac{1}{4 \cdot 2 - 3 \cdot 3}\begin{bmatrix} 2 & -3 \\ -3 & 4 \end{bmatrix}
= \begin{bmatrix} -2 & 3 \\ 3 & -4 \end{bmatrix}
$$

(Определитель: $\det(A) = -1$)

**Нормы** (в норме $\infty$):
$$
\|A\|_\infty = \max(4 + 3, 3 + 2) = 7
$$
$$
\|A^{-1}\|_\infty = \max(|-2| + 3, 3 + |-4|) = 7
$$

**Число обусловленности**:
$$
\kappa_\infty(A) = 7 \times 7 = 49
$$

**Интерпретация**: Умеренная обусловленность — ошибка данных может увеличиться до 50 раз.

### Пример: матрица с близкими к нулю собственными значениями

$$
A = \begin{bmatrix} 1 & 0.99 \\ 0.99 & 1 \end{bmatrix}
$$

**Собственные значения**: $\lambda_1 \approx 1.99$, $\lambda_2 \approx 0.01$

**Число обусловленности**:
$$
\kappa_2(A) = \frac{1.99}{0.01} = 199
$$

Умеренная обусловленность, но близость собственного значения к нулю — предупреждение.

### Пример: экстремально плохая обусловленность

**Матрица Гильберта** $H_5$:
$$
H_5 = \begin{bmatrix}
1 & 1/2 & 1/3 & 1/4 & 1/5 \\
1/2 & 1/3 & 1/4 & 1/5 & 1/6 \\
1/3 & 1/4 & 1/5 & 1/6 & 1/7 \\
1/4 & 1/5 & 1/6 & 1/7 & 1/8 \\
1/5 & 1/6 & 1/7 & 1/8 & 1/9
\end{bmatrix}
$$

$$
\kappa_2(H_5) \approx 4.77 \times 10^5
$$

**Потеря точности**: $\log_{10}(4.77 \times 10^5) \approx 5.7$ десятичных знаков

В двойной точности (16 знаков) остаётся только **10 точных знаков**.

### Сравнение: хорошая vs плохая обусловленность

**Хорошая обусловленность**:
$$
A = \begin{bmatrix} 2 & 0 \\ 0 & 3 \end{bmatrix}, \quad
\kappa_2(A) = \frac{3}{2} = 1.5
$$

Решение стабильно, малые ошибки данных → малые ошибки решения.

**Плохая обусловленность**:
$$
A = \begin{bmatrix} 1 & 1 \\ 1 & 1.00001 \end{bmatrix}, \quad
\kappa_2(A) \approx 2 \times 10^5
$$

Решение крайне чувствительно, ошибка $10^{-6}$ в данных → ошибка $10^{-1}$ в решении!

---

## Источник

- Документ: [[Линейная алгебра и ее применения.pdf]]
- Раздел/страницы: § 1.5, стр. 48–49
- Ключевая цитата:
  
  > «Одни матрицы чрезвычайно чувствительны к малым изменениям, а другие нет... К сожалению, нужно сказать, что **даже хорошо обусловленная матрица** может быть испорчена плохим алгоритмом исключения, и средство против этого видны уже теперь».

---

## Вопросы

- Как эффективно оценить $\kappa(A)$ без явного вычисления $A^{-1}$?
- Можно ли улучшить обусловленность предобуславливанием (preconditioning)?
- Как число обусловленности связано с углами между столбцами/строками матрицы?
- Существует ли связь между $\kappa(A)$ и скоростью сходимости итерационных методов?
- Как обобщается число обусловленности на прямоугольные матрицы и проблемы наименьших квадратов?